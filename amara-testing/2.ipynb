{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from importlib import reload\n",
    "import sys; sys.path.append('../../_Common')\n",
    "import amara; reload(amara)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from amara.static.groupings import taxes, breakfast_groups\n",
    "from amara.core.grouping import group_categories, group_thresholds\n",
    "from amara.core.wrappers import DirectoryWrapper, DataFrameWrapper\n",
    "\n",
    "from amara.datasets.Info_HMS_Raw_Arrivals import mend_arrival_departure_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# read data and consolidate\u001b[39;00m\n\u001b[0;32m      2\u001b[0m filepaths \u001b[39m=\u001b[39m DirectoryWrapper(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../../Raw Data/Info_HMS_Raw_Arrivals\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mfiles\n\u001b[1;32m----> 3\u001b[0m dfs: \u001b[39mlist\u001b[39m[pd\u001b[39m.\u001b[39mDataFrame] \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)(delayed(pd\u001b[39m.\u001b[39;49mread_excel)(filepath) \u001b[39mfor\u001b[39;49;00m filepath \u001b[39min\u001b[39;49;00m filepaths)\n\u001b[0;32m      4\u001b[0m InfoHMS_consolidated \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dfs)\u001b[39m.\u001b[39mdrop_duplicates(\u001b[39m'\u001b[39m\u001b[39mConfirmation Number\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\intern\\AppData\\Local\\anaconda3\\envs\\Amara\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\intern\\AppData\\Local\\anaconda3\\envs\\Amara\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\intern\\AppData\\Local\\anaconda3\\envs\\Amara\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\intern\\AppData\\Local\\anaconda3\\envs\\Amara\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\intern\\AppData\\Local\\anaconda3\\envs\\Amara\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# read data and consolidate\n",
    "filepaths = DirectoryWrapper(f'../../Raw Data/Info_HMS_Raw_Arrivals').files\n",
    "dfs: list[pd.DataFrame] = Parallel(n_jobs=-1, verbose=0)(delayed(pd.read_excel)(filepath) for filepath in filepaths)\n",
    "InfoHMS_consolidated = pd.concat(dfs).drop_duplicates('Confirmation Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = InfoHMS_consolidated.copy(deep=True)\n",
    "\n",
    "# remove unneeded columns\n",
    "extracted.drop(['3rd Conf # / Shipping', 'Scheduled Room', 'Room Change Today', 'A/R Account', 'Undelivered Messages', 'Channel'], axis=1, inplace=True)\n",
    "# extracted = extracted.loc[extracted['Arrival Date'].between(datetime(2023, 1, 1), datetime(2023, 6, 30), inclusive='both')]\n",
    "\n",
    "# split and mend Arrival/Departure dates\n",
    "InfoHMS_chunks = DataFrameWrapper(extracted).to_chunks(chunk_size=5_000)\n",
    "InfoHMS_chunks: list[pd.DataFrame] = Parallel(n_jobs=-1, verbose=0)(delayed(mend_arrival_departure_dates)(chunk) for chunk in InfoHMS_chunks)\n",
    "extracted = pd.concat(InfoHMS_chunks).sort_values('Arrival Date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extracted.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2948"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InfoHMS_consolidated.loc[InfoHMS_consolidated['Arrival Date'].between(datetime(2023, 1, 1), datetime(2023, 6, 30), inclusive='both')]['Nights'].sum() - extracted['Split Nights'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arrival Date</th>\n",
       "      <th>Departure Date</th>\n",
       "      <th>Split Nights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6116</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6130</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6138</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6207</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6210</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6235</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6237</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6242</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6246</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6255</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6257</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Arrival Date Departure Date  Split Nights\n",
       "2598   2023-02-01     2023-02-03             2\n",
       "2601   2023-02-01     2023-02-03             2\n",
       "2610   2023-02-01     2023-02-03             2\n",
       "2618   2023-02-01     2023-02-03             2\n",
       "2625   2023-02-01     2023-02-03             2\n",
       "2629   2023-02-01     2023-02-03             2\n",
       "2633   2023-02-01     2023-02-03             2\n",
       "2734   2023-02-01     2023-02-03             2\n",
       "2741   2023-02-01     2023-02-03             2\n",
       "2745   2023-02-01     2023-02-03             2\n",
       "2749   2023-02-01     2023-02-03             2\n",
       "6076   2023-02-27     2023-02-28             2\n",
       "6090   2023-02-27     2023-02-28             2\n",
       "6116   2023-02-27     2023-02-28             2\n",
       "6124   2023-02-27     2023-02-28             2\n",
       "6130   2023-02-27     2023-02-28             2\n",
       "6138   2023-02-27     2023-02-28             2\n",
       "6164   2023-02-28     2023-02-28             1\n",
       "6172   2023-02-28     2023-02-28             1\n",
       "6174   2023-02-28     2023-02-28             1\n",
       "6184   2023-02-28     2023-02-28             1\n",
       "6199   2023-02-28     2023-02-28             1\n",
       "6201   2023-02-28     2023-02-28             1\n",
       "6207   2023-02-28     2023-02-28             1\n",
       "6208   2023-02-28     2023-02-28             1\n",
       "6210   2023-02-28     2023-02-28             1\n",
       "6211   2023-02-28     2023-02-28             1\n",
       "6214   2023-02-28     2023-02-28             1\n",
       "6216   2023-02-28     2023-02-28             1\n",
       "6217   2023-02-28     2023-02-28             1\n",
       "6219   2023-02-28     2023-02-28             1\n",
       "6220   2023-02-28     2023-02-28             1\n",
       "6223   2023-02-28     2023-02-28             1\n",
       "6225   2023-02-28     2023-02-28             1\n",
       "6226   2023-02-28     2023-02-28             1\n",
       "6235   2023-02-28     2023-02-28             1\n",
       "6237   2023-02-28     2023-02-28             1\n",
       "6239   2023-02-28     2023-02-28             1\n",
       "6242   2023-02-28     2023-02-28             1\n",
       "6246   2023-02-28     2023-02-28             1\n",
       "6252   2023-02-28     2023-02-28             1\n",
       "6255   2023-02-28     2023-02-28             1\n",
       "6257   2023-02-28     2023-02-28             1"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\n",
    "    (df['Market Segment'] == 'Corp Group(Rooms w Meeting)') & \n",
    "    (df['Arrival Date'].dt.year == 2023) & \n",
    "    (df['Arrival Date'].dt.month == 2)\n",
    "][['Arrival Date', 'Departure Date', 'Split Nights']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = InfoHMS_consolidated.copy(deep=True)\n",
    "\n",
    "tax_percentage = np.array(group_thresholds(df['Arrival Date'].dt.year, taxes))\n",
    "df['Split Rate Grand Total'] = df['Split Rate Grand Total'] * (1 / tax_percentage)\n",
    "\n",
    "bf_cost = group_categories(df['Non-Room Bundle'], breakfast_groups, filler = 0)\n",
    "\n",
    "# set adults to 1, nights from 0 to 1 if bundle is '6BEERS'\n",
    "bf_adults = np.array([1 if row['Non-Room Bundle'] == '6BEERS' else row['Adults'] for _, row in df.iterrows()])\n",
    "bf_nights = df['Split Nights'].apply(lambda x: x if x > 0 else 1)\n",
    "\n",
    "bf_cost = np.array(bf_cost) * bf_nights * bf_adults\n",
    "df['Split Rate Grand Total'] = df['Split Rate Grand Total'] - bf_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline Crew                  0\n",
      "Airlines                      0\n",
      "Complimentary                 0.0\n",
      "Corp Group (Rooms Only)       26539.0\n",
      "Corp Group(Rooms w Meeting)   594.0000000000001\n",
      "Corporate FIT                 343703.75718637614\n",
      "Corporate Long Stay           3493.627525704933\n",
      "Corporate Volume              4261.0\n",
      "House-use                     0.0\n",
      "Internet                      920508.6599975992\n",
      "Leisure FIT                   260058.5483832706\n",
      "Lifetime Holidays (Member)    0.0\n",
      "Shipping                      194794.88696960686\n",
      "Wholesaler TA FIT             4636.560606060606\n",
      "Wholesaler TA Group           6285.989898989899\n"
     ]
    }
   ],
   "source": [
    "for mktseg in sorted(df['Market Segment'].unique()):\n",
    "    revenue = df.loc[\n",
    "        (df['Arrival Date'].between(datetime(2023, 2, 1), datetime(2023, 2, 28), inclusive='both')) & \n",
    "        (df['Market Segment'] == mktseg) & \n",
    "        (df['Status'] != 'No Show') & (df['Status'] != 'Cancelled')\n",
    "    ]['Split Rate Grand Total'].sum()\n",
    "\n",
    "    print(f'{mktseg: <30}{revenue}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arrival Date</th>\n",
       "      <th>Departure Date</th>\n",
       "      <th>Split Nights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158720</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158722</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158723</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158812</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158823</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158824</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158864</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158868</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158870</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158871</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158872</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161960</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161975</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161978</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161981</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161987</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161996</th>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162065</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162071</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162080</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162086</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162087</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162090</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162092</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162094</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162096</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162099</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162101</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162120</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162123</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162132</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162134</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162136</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162138</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162142</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162145</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162147</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162148</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162150</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162152</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162153</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162154</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162160</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Arrival Date Departure Date  Split Nights\n",
       "158720   2023-02-01     2023-02-03             2\n",
       "158722   2023-02-01     2023-02-03             2\n",
       "158723   2023-02-01     2023-02-03             2\n",
       "158812   2023-02-01     2023-02-03             2\n",
       "158823   2023-02-01     2023-02-03             2\n",
       "158824   2023-02-01     2023-02-03             2\n",
       "158864   2023-02-01     2023-02-03             2\n",
       "158868   2023-02-01     2023-02-03             2\n",
       "158870   2023-02-01     2023-02-03             2\n",
       "158871   2023-02-01     2023-02-03             2\n",
       "158872   2023-02-01     2023-02-03             2\n",
       "161960   2023-02-27     2023-02-28             1\n",
       "161975   2023-02-27     2023-02-28             1\n",
       "161978   2023-02-27     2023-02-28             1\n",
       "161981   2023-02-27     2023-02-28             1\n",
       "161987   2023-02-27     2023-02-28             1\n",
       "161996   2023-02-27     2023-02-28             1\n",
       "162065   2023-02-28     2023-02-28             0\n",
       "162071   2023-02-28     2023-02-28             0\n",
       "162080   2023-02-28     2023-02-28             0\n",
       "162086   2023-02-28     2023-02-28             0\n",
       "162087   2023-02-28     2023-02-28             0\n",
       "162090   2023-02-28     2023-02-28             0\n",
       "162092   2023-02-28     2023-02-28             0\n",
       "162094   2023-02-28     2023-02-28             0\n",
       "162096   2023-02-28     2023-02-28             0\n",
       "162099   2023-02-28     2023-02-28             0\n",
       "162101   2023-02-28     2023-02-28             0\n",
       "162120   2023-02-28     2023-02-28             0\n",
       "162123   2023-02-28     2023-02-28             0\n",
       "162132   2023-02-28     2023-02-28             0\n",
       "162134   2023-02-28     2023-02-28             0\n",
       "162136   2023-02-28     2023-02-28             0\n",
       "162138   2023-02-28     2023-02-28             0\n",
       "162142   2023-02-28     2023-02-28             0\n",
       "162145   2023-02-28     2023-02-28             0\n",
       "162147   2023-02-28     2023-02-28             0\n",
       "162148   2023-02-28     2023-02-28             0\n",
       "162150   2023-02-28     2023-02-28             0\n",
       "162152   2023-02-28     2023-02-28             0\n",
       "162153   2023-02-28     2023-02-28             0\n",
       "162154   2023-02-28     2023-02-28             0\n",
       "162160   2023-02-28     2023-02-28             0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\n",
    "    (df['Market Segment'] == 'Corp Group(Rooms w Meeting)') & \n",
    "    (df['Arrival Date'].dt.year == 2023) & \n",
    "    (df['Arrival Date'].dt.month == 2)\n",
    "][['Arrival Date', 'Departure Date', 'Split Nights']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakfast_groups = {\n",
    "    14 + 20 + 18: ['MUSETA'],\n",
    "    12 + 14.94 + 18: ['MUSETB'],\n",
    "    14: ['Internal ABF', 'Internal ABF - Bulk Buy'],\n",
    "    9: ['Club BF'],\n",
    "    8 + 14 + 12: ['SHN / PCA'],\n",
    "    2 + 3.5 + 3: ['McDonald PCA'],\n",
    "    13: ['High Tea'],\n",
    "    17.5: ['Dayuse - 3 course Set Lunch'],\n",
    "    39: ['6BEERS']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_cost = group_categories(df['Non-Room Bundle'], breakfast_groups, filler = 0)\n",
    "bf_adults = np.array([row['Adults'] if row['Non-Room Bundle'] != '6BEERS' else 1 for _, row in df.iterrows()])\n",
    "bf_nights = \n",
    "bf_cost = np.array(bf_cost) * df['Split Nights'] * bf_adults\n",
    "\n",
    "df['BF Cost'] = bf_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., 39.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Non-Room Bundle'] == '6BEERS']['BF Cost'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_cost = group_categories(df['Non-Room Bundle'], breakfast_groups, filler = 0)\n",
    "bf_cost = np.array(bf_cost) * df['Split Nights'] * df['Adults']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   7,   0,  11,   4,   5,   8,   6,  18,   9,  10,\n",
       "        14,  12,  24,  13,  19,  41,  29,  42,  16,  20,  32,  30,  15,\n",
       "        28, 120,  77,  17,  27,  25,  22,  23,  21,  26, 213,  64, 211,\n",
       "        63, 208,  61,  52,  50,  76,  57,  55,  51,  74, 199,  35, 198,\n",
       "        49,  33,  48,  39,  53,  46, 196,  45,  47,  44,  43,  40,  36,\n",
       "        38,  37, 186,  60,  34,  31,  59, 142, 140,  56, 139, 138, 137,\n",
       "        54, 136, 135, 132, 130, 126, 125,  89, 124, 122, 118, 116, 114,\n",
       "       112, 110, 108, 106, 104, 101,  99,  98,  97,  96,  95,  94,  92,\n",
       "        91,  90,  88,  87,  85,  83,  68,  81,  79,  78,  62,  75,  73,\n",
       "        72,  71,  70,  69,  67,  66, 153,  93, 159], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Split Rate Grand Total'] == bf_cost]['Nights'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rate Grand Total'] -= np.array(bf) * df['Adults'] * df['Nights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Complimentary', 'Lifetime Holidays (Member)', 'Corporate FIT',\n",
       "       'House-use', 'Leisure FIT', 'Wholesaler TA Group',\n",
       "       'Wholesaler TA FIT', 'Corp Group(Rooms w Meeting)', 'Airlines',\n",
       "       'Corporate Volume', 'Internet'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Rate Grand Total'] == 0]['Market Segment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1         104\n",
       "2          52\n",
       "3         104\n",
       "4         104\n",
       "         ... \n",
       "177892    NaN\n",
       "177893     42\n",
       "177894     28\n",
       "177895     14\n",
       "177896     14\n",
       "Name: Adults, Length: 177897, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(bf) * df['Adults']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84015"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(np.array(bf) * df['Adults']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Amara",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
